# âœï¸ Handwriting to Text Recognition (CRNN Model)

## ğŸ“Œ Overview

This project implements an end-to-end **Handwritten Text Recognition (HTR)** system using a **Convolutional Recurrent Neural Network (CRNN)** architecture.

The system converts handwritten word images into corresponding digital text. It effectively combines:
1.  **CNN layers** for visual feature extraction from the handwriting.
2.  **RNN layers (Bi-LSTMs)** for sequential context modeling.
3.  **CTC loss** for robust, alignment-free sequence decoding.

## âš™ï¸ System Workflow

### Dataset Preparation
* The **IAM Handwriting Dataset** is used for training and evaluation.
* Images are organized and labeled based on ground-truth transcriptions.

### Data Preprocessing
* Each image is converted to grayscale.
* Resized uniformly to **$128 \times 512$** for consistent input.
* Normalized and converted into PyTorch tensors.

### ğŸ§  Model Architecture

The CRNN pipeline sequentially processes the image to extract and decode features:

| Module | Purpose |
| :--- | :--- |
| **Feature Extraction (CNN)** | Convolutional layers extract spatial features, stroke patterns, and writing flow. |
| **Sequence Modeling (RNN)** | Bidirectional LSTMs capture sequential dependencies and context between characters. |
| **CTC Decoding** | **Connectionist Temporal Classification** maps the sequence output to variable-length character sequences, handling alignment dependencies. |

Input Image (1Ã—128Ã—512) â”‚ [CNN Layers] â”‚ Feature Maps â”‚ [BiLSTM Layers] â”‚ Sequence Output â”‚ [CTC Loss] â”‚ Predicted Text Output


### Evaluation
The model performance is measured using standard metrics: **Character Error Rate (CER)** and **Word Error Rate (WER)**.

---

## ğŸ“Š Results

The model was evaluated on unseen handwriting samples.

| Metric | Value |
| :--- | :--- |
| Samples Tested | **619** |
| Character Accuracy | **91.64%** |
| Character Error Rate (CER) | **0.0449** |
| Word Error Rate (WER) | **0.1470** |

### ğŸ“ˆ Performance Visualization

```python
import matplotlib.pyplot as plt

metrics = ['Character Accuracy', 'CER', 'WER']
values = [91.64, 0.0449, 0.1470]

plt.figure(figsize=(8, 5))
plt.plot(metrics, values, marker='o', color='teal', linewidth=2)
plt.title('Model Evaluation Metrics')
plt.ylabel('Value')
plt.grid(True)
plt.show()
```
ğŸš€ How to Run
1ï¸âƒ£ Clone the Repository
```
git clone [https://github.com/](https://github.com/)<your-username>/handwriting_to_text.git
cd handwriting_to_text
```

2ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```
3ï¸âƒ£ Prepare Dataset
Place the IAM Handwriting Dataset files inside the ./data/ directory or update the dataset path in dataloader.py.

4ï¸âƒ£ Train the Model
```
python train.py
```
5ï¸âƒ£ Evaluate the Model
```
python evaluate.py
```
6ï¸âƒ£ Predict on Custom Image
```
python predict.py --image <path_to_image>
```

ğŸ“‚ Project Structure
```
handwriting_to_text/
â”‚
â”œâ”€â”€ data/                       # Dataset folder
â”œâ”€â”€ models/                     # Trained models / checkpoints
â”œâ”€â”€ outputs/                    # Predictions and result images
â”œâ”€â”€ train.py                    # Model training script
â”œâ”€â”€ evaluate.py                 # Model evaluation script
â”œâ”€â”€ predict.py                  # Custom image prediction
â”œâ”€â”€ dataloader.py               # Dataset loader and transformations
â”œâ”€â”€ CRNN_model.py               # CRNN architecture definition
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # Project documentation
```
ğŸ§° Technologies Used
Python

PyTorch (for deep learning framework)

OpenCV

PIL (Pillow)

NumPy / Matplotlib

IAM Handwriting Dataset

ğŸ“– Future Enhancements
Integrate Transformer-based recognition models (e.g., Vision Transformers).

Add multi-language handwriting support.

Develop a web interface using Flask/Streamlit for easy demo.

Enable real-time handwriting recognition via webcam input.

ğŸ‘¨â€ğŸ’» Author
Dilip Kannan
